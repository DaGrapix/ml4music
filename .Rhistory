library(tidyverse)
library(cowplot)
library(ROCR)
library(MASS)
library(glmnet)
library(corrplot)
library(caret)
library(class)
library(doParallel)
prepare.data.test <- function(){
data <- read.csv("Music_test.txt",sep=";",header=TRUE)
data.0 <- read.csv("Music_test.txt",sep=";",header=TRUE)
data.0$PAR_SC_V <- log(data.0$PAR_SC_V)
data.0$PAR_ASC_V <- log(data.0$PAR_ASC_V)
indices.retires <- c(148:167)
data <- data.0[, -indices.retires]
corr <- cor(x=data[, -ncol(data)])
high.corr.index.new <- which(corr>0.99, arr.ind = TRUE) %>% unname
lower.tri <- lower.tri(corr, diag=FALSE)
high.corr.index.new <- high.corr.index.new[which(lower.tri[high.corr.index.new]==TRUE),]
correlated.variables <- matrix(c(names(data)[high.corr.index.new[,1]],
names(data)[high.corr.index.new[,2]]),
nrow=nrow(high.corr.index.new))
name.list <- as.vector(correlated.variables)
high.corr.index <- matrix(which(names(data.0) %in% name.list), nrow=nrow(high.corr.index.new))
indices.retires <- c(indices.retires, high.corr.index[,1])
indices.4 <- which(names(data.0) %in% c("PAR_ASE_M", "PAR_ASE_MV", "PAR_SFM_M", "PAR_SFM_MV"))
indices.retires <- c(indices.retires, indices.4)
names(data.0)[ncol(data.0)] = "y"
data.0$y <- ifelse(data.0$y=="Jazz", 1, 0)
## Echantillon d'apprentissage
set.seed(103)
train = sample(c(TRUE,FALSE), nrow(data.0), rep=TRUE, prob=c(2/3,1/3))
#On retirera les variables plus tard
data.train.0 <- data.0[which(train),]
data.test.0 <- data.0[which(train==FALSE),]
#On retire les 27 variables
data <- data.0[, -indices.retires]
data.train <- data.train.0[, -indices.retires]
data.test <- data.test.0[, -indices.retires]
return(list(data=data, data.train=data.train, data.test=data.test, data.0=data.0, data.train.0=data.train.0, data.test.0=data.test.0))
}
prepare.data.unlabelled <- function(){
data <- read.csv("Music_test.txt",sep=";",header=TRUE)
data.0 <- read.csv("Music_test.txt",sep=";",header=TRUE)
data.0$PAR_SC_V <- log(data.0$PAR_SC_V)
data.0$PAR_ASC_V <- log(data.0$PAR_ASC_V)
indices.retires <- c(148:167)
data <- data.0[, -indices.retires]
corr <- cor(x=data[, -ncol(data)])
high.corr.index.new <- which(corr>0.99, arr.ind = TRUE) %>% unname
lower.tri <- lower.tri(corr, diag=FALSE)
high.corr.index.new <- high.corr.index.new[which(lower.tri[high.corr.index.new]==TRUE),]
correlated.variables <- matrix(c(names(data)[high.corr.index.new[,1]],
names(data)[high.corr.index.new[,2]]),
nrow=nrow(high.corr.index.new))
name.list <- as.vector(correlated.variables)
high.corr.index <- matrix(which(names(data.0) %in% name.list), nrow=nrow(high.corr.index.new))
indices.retires <- c(indices.retires, high.corr.index[,1])
indices.4 <- which(names(data.0) %in% c("PAR_ASE_M", "PAR_ASE_MV", "PAR_SFM_M", "PAR_SFM_MV"))
indices.retires <- c(indices.retires, indices.4)
names(data.0)[ncol(data.0)] = "y"
data.0$y <- ifelse(data.0$y=="Jazz", 1, 0)
## Echantillon d'apprentissage
set.seed(103)
train = sample(c(TRUE,FALSE), nrow(data.0), rep=TRUE, prob=c(2/3,1/3))
#On retirera les variables plus tard
data.train.0 <- data.0[which(train),]
data.test.0 <- data.0[which(train==FALSE),]
#On retire les 27 variables
data <- data.0[, -indices.retires]
data.train <- data.train.0[, -indices.retires]
data.test <- data.test.0[, -indices.retires]
return(list(data=data, data.train=data.train, data.test=data.test, data.0=data.0, data.train.0=data.train.0, data.test.0=data.test.0))
}
df <- prepare.data.unlabelled()
setwd(getwd())
df <- prepare.data.unlabelled()
setwd("F:/ZZ/sta203_projet")
df <- prepare.data.unlabelled()
prepare.data.unlabelled <- function(){
data <- read.csv("Music_2023.txt",sep=";",header=TRUE)
data.0 <- read.csv("Music_2023.txt",sep=";",header=TRUE)
data.unlabelled <- read.csv("Music_test.txt",sep=";",header=TRUE)
data.unlabelled$PAR_SC_V <- log(data.unlabelled$PAR_SC_V)
data.unlabelled$PAR_ASC_V <- log(data.unlabelled$PAR_ASC_V)
##indices à retirer
indices.retires <- c(148:167)
data <- data.0[, -indices.retires]
corr <- cor(x=data[, -ncol(data)])
high.corr.index.new <- which(corr>0.99, arr.ind = TRUE) %>% unname
lower.tri <- lower.tri(corr, diag=FALSE)
high.corr.index.new <- high.corr.index.new[which(lower.tri[high.corr.index.new]==TRUE),]
correlated.variables <- matrix(c(names(data)[high.corr.index.new[,1]],
names(data)[high.corr.index.new[,2]]),
nrow=nrow(high.corr.index.new))
name.list <- as.vector(correlated.variables)
high.corr.index <- matrix(which(names(data.0) %in% name.list), nrow=nrow(high.corr.index.new))
indices.retires <- c(indices.retires, high.corr.index[,1])
indices.4 <- which(names(data.0) %in% c("PAR_ASE_M", "PAR_ASE_MV", "PAR_SFM_M", "PAR_SFM_MV"))
indices.retires <- c(indices.retires, indices.4)
print(indices.retires)
#On retire les 27 variables
data.unlabelled <- data.unlabelled[, -indices.retires]
return(list(data.unlabelled=data.unlabelled))
}
df <- prepare.data.unlabelled()
#Importation et nettoyage des donnees
prepare.data <- function(){
data <- read.csv("Music_2023.txt",sep=";",header=TRUE)
data.0 <- read.csv("Music_2023.txt",sep=";",header=TRUE)
data.0$PAR_SC_V <- log(data.0$PAR_SC_V)
data.0$PAR_ASC_V <- log(data.0$PAR_ASC_V)
indices.retires <- c(148:167)
data <- data.0[, -indices.retires]
corr <- cor(x=data[, -ncol(data)])
high.corr.index.new <- which(corr>0.99, arr.ind = TRUE) %>% unname
lower.tri <- lower.tri(corr, diag=FALSE)
high.corr.index.new <- high.corr.index.new[which(lower.tri[high.corr.index.new]==TRUE),]
correlated.variables <- matrix(c(names(data)[high.corr.index.new[,1]],
names(data)[high.corr.index.new[,2]]),
nrow=nrow(high.corr.index.new))
name.list <- as.vector(correlated.variables)
high.corr.index <- matrix(which(names(data.0) %in% name.list), nrow=nrow(high.corr.index.new))
indices.retires <- c(indices.retires, high.corr.index[,1])
indices.4 <- which(names(data.0) %in% c("PAR_ASE_M", "PAR_ASE_MV", "PAR_SFM_M", "PAR_SFM_MV"))
indices.retires <- c(indices.retires, indices.4)
names(data.0)[ncol(data.0)] = "y"
data.0$y <- ifelse(data.0$y=="Jazz", 1, 0)
## Echantillon d'apprentissage
set.seed(103)
train = sample(c(TRUE,FALSE), nrow(data.0), rep=TRUE, prob=c(2/3,1/3))
#On retirera les variables plus tard
data.train.0 <- data.0[which(train),]
data.test.0 <- data.0[which(train==FALSE),]
#On retire les 27 variables
data <- data.0[, -indices.retires]
data.train <- data.train.0[, -indices.retires]
data.test <- data.test.0[, -indices.retires]
print(indices.retires)
return(list(data=data, data.train=data.train, data.test=data.test, data.0=data.0, data.train.0=data.train.0, data.test.0=data.test.0))
}
df <- prepare.data()
df <- prepare.data.unlabelled("Music_2023.txt")
prepare.data.unlabelled <- function(filename){
data <- read.csv("Music_2023.txt",sep=";",header=TRUE)
data.0 <- read.csv("Music_2023.txt",sep=";",header=TRUE)
data.unlabelled <- read.csv(filename,sep=";",header=TRUE)
data.unlabelled$PAR_SC_V <- log(data.unlabelled$PAR_SC_V)
data.unlabelled$PAR_ASC_V <- log(data.unlabelled$PAR_ASC_V)
##indices à retirer
indices.retires <- c(148:167)
data <- data.0[, -indices.retires]
corr <- cor(x=data[, -ncol(data)])
high.corr.index.new <- which(corr>0.99, arr.ind = TRUE) %>% unname
lower.tri <- lower.tri(corr, diag=FALSE)
high.corr.index.new <- high.corr.index.new[which(lower.tri[high.corr.index.new]==TRUE),]
correlated.variables <- matrix(c(names(data)[high.corr.index.new[,1]],
names(data)[high.corr.index.new[,2]]),
nrow=nrow(high.corr.index.new))
name.list <- as.vector(correlated.variables)
high.corr.index <- matrix(which(names(data.0) %in% name.list), nrow=nrow(high.corr.index.new))
indices.retires <- c(indices.retires, high.corr.index[,1])
indices.4 <- which(names(data.0) %in% c("PAR_ASE_M", "PAR_ASE_MV", "PAR_SFM_M", "PAR_SFM_MV"))
indices.retires <- c(indices.retires, indices.4)
print(indices.retires)
#On retire les 27 variables
data.unlabelled <- data.unlabelled[, -indices.retires]
return(list(data.unlabelled=data.unlabelled))
}
df <- prepare.data.unlabelled("Music_2023.txt")
prepare.data.unlabelled <- function(filename){
data <- read.csv("Music_2023.txt",sep=";",header=TRUE)
data.0 <- read.csv("Music_2023.txt",sep=";",header=TRUE)
data.unlabelled <- read.csv(filename,sep=";",header=TRUE)
data.unlabelled$PAR_SC_V <- log(data.unlabelled$PAR_SC_V)
data.unlabelled$PAR_ASC_V <- log(data.unlabelled$PAR_ASC_V)
##indices à retirer
indices.retires <- c(148:167)
data <- data.0[, -indices.retires]
corr <- cor(x=data[, -ncol(data)])
high.corr.index.new <- which(corr>0.99, arr.ind = TRUE) %>% unname
lower.tri <- lower.tri(corr, diag=FALSE)
high.corr.index.new <- high.corr.index.new[which(lower.tri[high.corr.index.new]==TRUE),]
correlated.variables <- matrix(c(names(data)[high.corr.index.new[,1]],
names(data)[high.corr.index.new[,2]]),
nrow=nrow(high.corr.index.new))
name.list <- as.vector(correlated.variables)
high.corr.index <- matrix(which(names(data.0) %in% name.list), nrow=nrow(high.corr.index.new))
indices.retires <- c(indices.retires, high.corr.index[,1])
indices.4 <- which(names(data.0) %in% c("PAR_ASE_M", "PAR_ASE_MV", "PAR_SFM_M", "PAR_SFM_MV"))
indices.retires <- c(indices.retires, indices.4)
#On retire les variables
data.unlabelled <- data.unlabelled[, -indices.retires]
return(data.unlabelled)
}
data.unlabelled <- prepare.data.unlabelled("Music_2023.txt")
set.seed(314)
grid <- 10^seq(0, -5, length=100)
cv.out <- cv.glmnet(x=x.train, y=y.train, lambda=grid, nfolds=10)
rm(list=objects())
setwd(getwd())
library(ggplot2)
library(plyr)
library(stats)
library(tidyverse)
library(cowplot)
library(ROCR)
library(MASS)
library(glmnet)
library(corrplot)
library(caret)
library(class)
library(doParallel)
#Importation et nettoyage des donnees
prepare.data <- function(){
data <- read.csv("Music_2023.txt",sep=";",header=TRUE)
data.0 <- read.csv("Music_2023.txt",sep=";",header=TRUE)
data.0$PAR_SC_V <- log(data.0$PAR_SC_V)
data.0$PAR_ASC_V <- log(data.0$PAR_ASC_V)
indices.retires <- c(148:167)
data <- data.0[, -indices.retires]
corr <- cor(x=data[, -ncol(data)])
high.corr.index.new <- which(corr>0.99, arr.ind = TRUE) %>% unname
lower.tri <- lower.tri(corr, diag=FALSE)
high.corr.index.new <- high.corr.index.new[which(lower.tri[high.corr.index.new]==TRUE),]
correlated.variables <- matrix(c(names(data)[high.corr.index.new[,1]],
names(data)[high.corr.index.new[,2]]),
nrow=nrow(high.corr.index.new))
name.list <- as.vector(correlated.variables)
high.corr.index <- matrix(which(names(data.0) %in% name.list), nrow=nrow(high.corr.index.new))
indices.retires <- c(indices.retires, high.corr.index[,1])
indices.4 <- which(names(data.0) %in% c("PAR_ASE_M", "PAR_ASE_MV", "PAR_SFM_M", "PAR_SFM_MV"))
indices.retires <- c(indices.retires, indices.4)
names(data.0)[ncol(data.0)] = "y"
data.0$y <- ifelse(data.0$y=="Jazz", 1, 0)
## Echantillon d'apprentissage
set.seed(103)
train = sample(c(TRUE,FALSE), nrow(data.0), rep=TRUE, prob=c(2/3,1/3))
#On retirera les variables plus tard
data.train.0 <- data.0[which(train),]
data.test.0 <- data.0[which(train==FALSE),]
#On retire les 27 variables
data <- data.0[, -indices.retires]
data.train <- data.train.0[, -indices.retires]
data.test <- data.test.0[, -indices.retires]
return(list(data=data, data.train=data.train, data.test=data.test, data.0=data.0, data.train.0=data.train.0, data.test.0=data.test.0))
}
prepare.data.unlabelled <- function(filename){
data <- read.csv("Music_2023.txt",sep=";",header=TRUE)
data.0 <- read.csv("Music_2023.txt",sep=";",header=TRUE)
data.unlabelled <- read.csv(filename,sep=";",header=TRUE)
data.unlabelled$PAR_SC_V <- log(data.unlabelled$PAR_SC_V)
data.unlabelled$PAR_ASC_V <- log(data.unlabelled$PAR_ASC_V)
##indices à retirer
indices.retires <- c(148:167)
data <- data.0[, -indices.retires]
corr <- cor(x=data[, -ncol(data)])
high.corr.index.new <- which(corr>0.99, arr.ind = TRUE) %>% unname
lower.tri <- lower.tri(corr, diag=FALSE)
high.corr.index.new <- high.corr.index.new[which(lower.tri[high.corr.index.new]==TRUE),]
correlated.variables <- matrix(c(names(data)[high.corr.index.new[,1]],
names(data)[high.corr.index.new[,2]]),
nrow=nrow(high.corr.index.new))
name.list <- as.vector(correlated.variables)
high.corr.index <- matrix(which(names(data.0) %in% name.list), nrow=nrow(high.corr.index.new))
indices.retires <- c(indices.retires, high.corr.index[,1])
indices.4 <- which(names(data.0) %in% c("PAR_ASE_M", "PAR_ASE_MV", "PAR_SFM_M", "PAR_SFM_MV"))
indices.retires <- c(indices.retires, indices.4)
#On retire les variables
data.unlabelled <- data.unlabelled[, -indices.retires]
return(data.unlabelled)
}
df <- prepare.data()
data <- df$data
data.train <- df$data.train
data.test <- df$data.test
data.0 <- df$data.0
data.train.0 <- df$data.train.0
data.test.0 <- df$data.test.0
data.unlabelled <- prepare.data.unlabelled("Music_test.txt")
x.train <- data.train[,-ncol(data.train)] %>% as.matrix()
y.train <- data.train[,ncol(data.train)]
x.unlabelled<- data.unlabelled %>% as.matrix()
set.seed(314)
grid <- 10^seq(0, -5, length=100)
cv.out <- cv.glmnet(x=x.train, y=y.train, lambda=grid, nfolds=10)
bestlam=cv.out$lambda.min
plot(cv.out)
bestlam
## Prédiction
ridge.pred = predict(cv.out, alpha=0, s=bestlam, newx=data.unlabelled)
data.unlabelled
as.matrix(data.unlabelled)
x.unlabelled <- data.unlabelled %>% as.matrix()
## Prédiction
ridge.pred = predict(cv.out, alpha=0, s=bestlam, newx=x.unlabelled)
## Prédiction
ridge.pred <- predict(cv.out, alpha=0, s=bestlam, newx=x.unlabelled)
ridge.pred
## Prédiction
ridge.pred <- predict(cv.out, alpha=0, s=bestlam, newx=x.unlabelled)
ridge.pred <- ifelse(abs(ridge.pred)<0.1, "Classical", "Jazz")
## Prédiction
ridge.pred <- predict(cv.out, alpha=0, s=bestlam, newx=x.unlabelled)
ridge.pred <- ifelse(abs(ridge.pred)<0.1, "Classical", "Jazz")
ridge.pred
dim(data.unlabelled)
ridge.pred
write.table(ridge.pred, file="KALAYDJIAN-OCCHIPINTI_test.txt", sep=", ")
ridge.pred %>% unname() %>% as.matrix()
prediction <- c(ridge.pred)
prediction
write.table(prediction, file="KALAYDJIAN-OCCHIPINTI_test.txt", sep=", ")
write.table(prediction, file="KALAYDJIAN-OCCHIPINTI_test.txt", sep=", ")
write.table(prediction, file="KALAYDJIAN-OCCHIPINTI_test.txt", sep=", ", row.names = FALSE)
prediction <- c(ridge.pred) %>% unname()
write.table(prediction, file="KALAYDJIAN-OCCHIPINTI_test.txt", sep=", ", row.names = FALSE)
prediction[1]
write.table(prediction, file="KALAYDJIAN-OCCHIPINTI_test.txt", sep=", ", row.names = FALSE, col.names = FALSE)
write.table(prediction, file="KALAYDJIAN-OCCHIPINTI_test.txt", row.names=FALSE, col.names=FALSE, quote=FALSE)
write.table(prediction, file="KALAYDJIAN-OCCHIPINTI_test.txt", sep=": ", row.names=TRUE, col.names=FALSE, quote=FALSE)
rm(list=objects())
rm(list=objects())
setwd(getwd())
library(glmnet)
#Importation et nettoyage des donnees
prepare.data <- function(){
data <- read.csv("Music_2023.txt",sep=";",header=TRUE)
data.0 <- read.csv("Music_2023.txt",sep=";",header=TRUE)
data.0$PAR_SC_V <- log(data.0$PAR_SC_V)
data.0$PAR_ASC_V <- log(data.0$PAR_ASC_V)
indices.retires <- c(148:167)
data <- data.0[, -indices.retires]
corr <- cor(x=data[, -ncol(data)])
high.corr.index.new <- which(corr>0.99, arr.ind = TRUE) %>% unname
lower.tri <- lower.tri(corr, diag=FALSE)
high.corr.index.new <- high.corr.index.new[which(lower.tri[high.corr.index.new]==TRUE),]
correlated.variables <- matrix(c(names(data)[high.corr.index.new[,1]],
names(data)[high.corr.index.new[,2]]),
nrow=nrow(high.corr.index.new))
name.list <- as.vector(correlated.variables)
high.corr.index <- matrix(which(names(data.0) %in% name.list), nrow=nrow(high.corr.index.new))
indices.retires <- c(indices.retires, high.corr.index[,1])
indices.4 <- which(names(data.0) %in% c("PAR_ASE_M", "PAR_ASE_MV", "PAR_SFM_M", "PAR_SFM_MV"))
indices.retires <- c(indices.retires, indices.4)
names(data.0)[ncol(data.0)] = "y"
data.0$y <- ifelse(data.0$y=="Jazz", 1, 0)
## Echantillon d'apprentissage
set.seed(103)
train = sample(c(TRUE,FALSE), nrow(data.0), rep=TRUE, prob=c(2/3,1/3))
#On retirera les variables plus tard
data.train.0 <- data.0[which(train),]
data.test.0 <- data.0[which(train==FALSE),]
#On retire les 27 variables
data <- data.0[, -indices.retires]
data.train <- data.train.0[, -indices.retires]
data.test <- data.test.0[, -indices.retires]
return(list(data=data, data.train=data.train, data.test=data.test, data.0=data.0, data.train.0=data.train.0, data.test.0=data.test.0))
}
prepare.data.unlabelled <- function(filename){
data <- read.csv("Music_2023.txt",sep=";",header=TRUE)
data.0 <- read.csv("Music_2023.txt",sep=";",header=TRUE)
data.unlabelled <- read.csv(filename,sep=";",header=TRUE)
data.unlabelled$PAR_SC_V <- log(data.unlabelled$PAR_SC_V)
data.unlabelled$PAR_ASC_V <- log(data.unlabelled$PAR_ASC_V)
##indices à retirer
indices.retires <- c(148:167)
data <- data.0[, -indices.retires]
corr <- cor(x=data[, -ncol(data)])
high.corr.index.new <- which(corr>0.99, arr.ind = TRUE) %>% unname
lower.tri <- lower.tri(corr, diag=FALSE)
high.corr.index.new <- high.corr.index.new[which(lower.tri[high.corr.index.new]==TRUE),]
correlated.variables <- matrix(c(names(data)[high.corr.index.new[,1]],
names(data)[high.corr.index.new[,2]]),
nrow=nrow(high.corr.index.new))
name.list <- as.vector(correlated.variables)
high.corr.index <- matrix(which(names(data.0) %in% name.list), nrow=nrow(high.corr.index.new))
indices.retires <- c(indices.retires, high.corr.index[,1])
indices.4 <- which(names(data.0) %in% c("PAR_ASE_M", "PAR_ASE_MV", "PAR_SFM_M", "PAR_SFM_MV"))
indices.retires <- c(indices.retires, indices.4)
#On retire les variables
data.unlabelled <- data.unlabelled[, -indices.retires]
return(data.unlabelled)
}
df <- prepare.data()
data <- df$data
data.train <- df$data.train
data.test <- df$data.test
data.0 <- df$data.0
data.train.0 <- df$data.train.0
data.test.0 <- df$data.test.0
df <- prepare.data()
data <- df$data
data.train <- df$data.train
data.test <- df$data.test
df <- prepare.data()
#On entraîne le modèle sur tout les individus du dataset
data.train <- df$data
data.unlabelled <- prepare.data.unlabelled("Music_test.txt")
dim(data.train)
data.unlabelled <- prepare.data.unlabelled("Music_test.txt")
dim(data.unlabelled)
x.train <- data.train[,-ncol(data.train)] %>% as.matrix()
y.train <- data.train[,ncol(data.train)]
x.unlabelled <- data.unlabelled %>% as.matrix()
#Modèle de régression ridge
set.seed(314)
grid <- 10^seq(0, -5, length=100)
cv.out <- cv.glmnet(x=x.train, y=y.train, lambda=grid, nfolds=10)
bestlam=cv.out$lambda.min
plot(cv.out)
bestlam
## Prédiction
ridge.pred <- predict(cv.out, alpha=0, s=bestlam, newx=x.unlabelled)
ridge.pred <- ifelse(abs(ridge.pred)<0.1, "Classical", "Jazz")
ridge.pred
prediction <- c(ridge.pred) %>% unname()
write.table(prediction, file="KALAYDJIAN-OCCHIPINTI_new.txt", sep=": ", row.names=TRUE, col.names=FALSE, quote=FALSE)
one <- read.table("KALAYDJIAN-OCCHIPINTI_new.txt", sep=": ")
one <- read.table("KALAYDJIAN-OCCHIPINTI_new.txt")
one
one[2]
dim(one)
two <- read.table("KALAYDJIAN-OCCHIPINTI_test.txt")
mean(one[,2] != two[,2])
write.table(prediction, file="KALAYDJIAN-OCCHIPINTI_test.txt", sep=": ", row.names=FALSE, col.names=FALSE, quote=FALSE)
prediction <- c(ridge.pred) %>% unname()
write.table(prediction, file="KALAYDJIAN-OCCHIPINTI_test.txt", sep=": ", row.names=FALSE, col.names=FALSE, quote=FALSE)
rm(list=objects())
setwd(getwd())
library(glmnet)
#Importation et nettoyage des donnees
prepare.data <- function(){
data <- read.csv("Music_2023.txt",sep=";",header=TRUE)
data.0 <- read.csv("Music_2023.txt",sep=";",header=TRUE)
data.0$PAR_SC_V <- log(data.0$PAR_SC_V)
data.0$PAR_ASC_V <- log(data.0$PAR_ASC_V)
indices.retires <- c(148:167)
data <- data.0[, -indices.retires]
corr <- cor(x=data[, -ncol(data)])
high.corr.index.new <- which(corr>0.99, arr.ind = TRUE) %>% unname
lower.tri <- lower.tri(corr, diag=FALSE)
high.corr.index.new <- high.corr.index.new[which(lower.tri[high.corr.index.new]==TRUE),]
correlated.variables <- matrix(c(names(data)[high.corr.index.new[,1]],
names(data)[high.corr.index.new[,2]]),
nrow=nrow(high.corr.index.new))
name.list <- as.vector(correlated.variables)
high.corr.index <- matrix(which(names(data.0) %in% name.list), nrow=nrow(high.corr.index.new))
indices.retires <- c(indices.retires, high.corr.index[,1])
indices.4 <- which(names(data.0) %in% c("PAR_ASE_M", "PAR_ASE_MV", "PAR_SFM_M", "PAR_SFM_MV"))
indices.retires <- c(indices.retires, indices.4)
names(data.0)[ncol(data.0)] = "y"
data.0$y <- ifelse(data.0$y=="Jazz", 1, 0)
## Echantillon d'apprentissage
set.seed(103)
train = sample(c(TRUE,FALSE), nrow(data.0), rep=TRUE, prob=c(2/3,1/3))
#On retirera les variables plus tard
data.train.0 <- data.0[which(train),]
data.test.0 <- data.0[which(train==FALSE),]
#On retire les 27 variables
data <- data.0[, -indices.retires]
data.train <- data.train.0[, -indices.retires]
data.test <- data.test.0[, -indices.retires]
return(list(data=data, data.train=data.train, data.test=data.test, data.0=data.0, data.train.0=data.train.0, data.test.0=data.test.0))
}
prepare.data.unlabelled <- function(filename){
data <- read.csv("Music_2023.txt",sep=";",header=TRUE)
data.0 <- read.csv("Music_2023.txt",sep=";",header=TRUE)
data.unlabelled <- read.csv(filename,sep=";",header=TRUE)
data.unlabelled$PAR_SC_V <- log(data.unlabelled$PAR_SC_V)
data.unlabelled$PAR_ASC_V <- log(data.unlabelled$PAR_ASC_V)
##indices à retirer
indices.retires <- c(148:167)
data <- data.0[, -indices.retires]
corr <- cor(x=data[, -ncol(data)])
high.corr.index.new <- which(corr>0.99, arr.ind = TRUE) %>% unname
lower.tri <- lower.tri(corr, diag=FALSE)
high.corr.index.new <- high.corr.index.new[which(lower.tri[high.corr.index.new]==TRUE),]
correlated.variables <- matrix(c(names(data)[high.corr.index.new[,1]],
names(data)[high.corr.index.new[,2]]),
nrow=nrow(high.corr.index.new))
name.list <- as.vector(correlated.variables)
high.corr.index <- matrix(which(names(data.0) %in% name.list), nrow=nrow(high.corr.index.new))
indices.retires <- c(indices.retires, high.corr.index[,1])
indices.4 <- which(names(data.0) %in% c("PAR_ASE_M", "PAR_ASE_MV", "PAR_SFM_M", "PAR_SFM_MV"))
indices.retires <- c(indices.retires, indices.4)
#On retire les variables
data.unlabelled <- data.unlabelled[, -indices.retires]
return(data.unlabelled)
}
df <- prepare.data()
#On entraîne le modèle sur tout les individus du dataset
data.train <- df$data
data.unlabelled <- prepare.data.unlabelled("Music_test.txt")
x.train <- data.train[,-ncol(data.train)] %>% as.matrix()
y.train <- data.train[,ncol(data.train)]
x.unlabelled <- data.unlabelled %>% as.matrix()
#Modèle de régression ridge
set.seed(314)
grid <- 10^seq(0, -5, length=100)
cv.out <- cv.glmnet(x=x.train, y=y.train, lambda=grid, nfolds=10)
bestlam=cv.out$lambda.min
plot(cv.out)
bestlam
#on trouve 0.0009326033 qui n'est pas sur la frontière, c'est le lambda optimal.
## Prédiction
ridge.pred <- predict(cv.out, alpha=0, s=bestlam, newx=x.unlabelled)
ridge.pred <- ifelse(abs(ridge.pred)<0.1, "Classical", "Jazz")
ridge.pred
prediction <- c(ridge.pred) %>% unname()
write.table(prediction, file="KALAYDJIAN-OCCHIPINTI_test.txt", sep=": ", row.names=FALSE, col.names=FALSE, quote=FALSE)
