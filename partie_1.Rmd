
```{r Librairie,include=FALSE, results='hide'}
library(ggplot2)
library(plyr)
library(stats)
library(tidyverse)
library(cowplot)
library(ROCR)

rm(list=ls())
```
## Analyse descriptive

On commence par importer les données et regarder de manière générale de quoi est composé notre jeu de donnée.

```{r import,include=TRUE}
setwd(getwd())
data <- read.csv("Music_2023.txt",sep=";",header=TRUE)

dim(data)
n <- nrow(data)
p <- ncol(data)
```


```{r import,include=TRUE}
par(mfrow=c(2,2))

data.mean.ASE <- apply(data[,4:37], MARGIN=1, FUN=mean)
plot(x=data.mean.ASE, y=data$PAR_ASE_M)

data.mean.ASEV <- apply(data[,39:72], MARGIN=1, FUN=mean)
plot(x=data.mean.ASEV, y=data$PAR_ASE_MV)

data.mean.SFM <-apply(data[,78:101], MARGIN=1, FUN=mean)
plot(x=data.mean.SFM_M, y=data$PAR_SFM_M)

data.mean.SFMV <-apply(data[,103:126], MARGIN=1, FUN=mean)
plot(x=data.mean.SFMV_M, y=data$PAR_SFM_MV)
```

Les dimensions du dataset importé sont correctes. Il y a bien 192 variables pour 4278 vecteurs de données.


```{r, R.options=list(max.print=5)}
summary(data)
```


```{r}
## A FAIRE : Analyse uni-bi variée

##Question : Comment choisir les variables qu'on observe ? 
```

```{r frequences,include=TRUE}
# Proportion des genres musicaux
freq<-plyr::count(data,'GENRE')

freq

prop_classical<-freq[1,2]/n
prop_jazz<-freq[2,2]/n

prop_classical
prop_jazz
```


Il est indiqué dans la description du jeu de donnée, que les variables 148 à 167 sont les mêmes que celles de 128 à 147. Ainsi, on peut s'en séparer sans risquer de perdre de l'information sur notre jeu de donnée. C'est d'ailleurs d'autant plus intéressant de les retirer, puisque cela réduit la dimmension et la complexité du modèle.



```{r transformation doublons}
data <- data[,-c(128:147)]
n <- nrow(data)
p <- ncol(data)
dim(data)
```
Il reste bien 172 variables pour 4278 vecteurs de données.


Par ailleurs, on remarque que les variables PAR_SC_V et PAR_ASC_V ont des distributions qui ne sont pas gaussiennes avant la transformation log au contraire des autres variables comme PAR_SC.

```{r Distribution et transformation log,echo=TRUE}
density_plot = function(X,xlab,lxlab){
  density<-ggplot(data,aes(x=X))+geom_density(col="blue")+xlab(xlab)
  log_density<-ggplot(data,aes(x=log(X)))+geom_density(col="red")+xlab(lxlab)
  plot_grid(density,log_density,labels=c("Densité","Densité log"),label_size=12,ncol=1,label_x = 0, label_y = 0,hjust = -0.5, vjust = -0.5)
}

density_plot(data$PAR_SC,xlab="PAR_SC",lxlab="log(PAR_SC)")
density_plot(data$PAR_SC_V,xlab="PAR_SC_V",lxlab="log(PAR_SC_V)")
density_plot(data$PAR_ASC_V,xlab="PAR_ASC_V",lxlab="log(PAR_ASC_V)")
```

On leur applique donc une transformation log.

```{r transformation log,echo=FALSE}
data$PAR_SC_V <- log(data$PAR_SC_V)
data$PAR_ASC_V <- log(data$PAR_ASC_V)

density_plot(data$PAR_SC,xlab="PAR_SC",lxlab="log(PAR_SC)")
density_plot(data$PAR_SC_V,xlab="PAR_SC_V",lxlab="log(PAR_SC_V)")
density_plot(data$PAR_ASC_V,xlab="PAR_ASC_V",lxlab="log(PAR_ASC_V)")
```


### Variables très corrélées
```{r}
corr <- cor(x=data[,-p])

#selection des indices de la matrice de correlation > 0.99
high.corr.index.new <- which(corr > 0.99, arr.ind = TRUE) %>% unname

#selection des indices appartenant a la matrice triangulaire inferieure stricte,
#pour retirer les doublons, ainsi que les elements diagonaux.
lower.tri <- lower.tri(corr, diag=FALSE)
high.corr.index.new <- high.corr.index.new[which(lower.tri[high.corr.index.new]==TRUE),]
high.corr.index.new
```

Nom des variables corrélées:
```{r variables corrélées}
correlated.variables <- matrix(c(names(data)[high.corr.index.new[,1]], 
                         names(data)[high.corr.index.new[,2]]), nrow=nrow(high.corr.index.new))
correlated.variables
```

Indices des variables corrélées dans le dataframe original:
```{r indices dans le df original, include=FALSE}
name.list <- as.vector(correlated.variables)
high.corr.index <- matrix(which(names(data) %in% name.list), nrow=nrow(high.corr.index.new))
high.corr.index
```

On remarque que les deux premiers couples de variables très corrélées sont en fait
les deux dernières mesures associées respectivement aux variables PAR_ASE et PAR_ASEV.

Le dernier couple de corrélation très élevée montre que la variable *PAR_ZCD* est très corrélée
avec *PAR_ZCD_10FR_MEAN* dont le nom semble qu'il s'agit d'une moyenne des *PAR_ZCD*.

On veillera à bien retirer à chaque fois l'une des deux variables très corrélées,
en effet les garder augmenterait la dimmension et la complexité du modèle, sans pour autant
apporter de l'information utile.

On retirera par exemple les variables *PAR_ASE34*, *PAR_ASEV34* et *PAR_ZCD_10FR_MEAN*.

```{r}
data <- data[,-high.corr.index.new[,1]]
n <- nrow(data)
p <- ncol(data)

dim(data)
```
Il reste bien 169 variables pour 4278 vecteurs de données.







### Cas des variables *PAR_ASE_M*, *PAR_ASE_MV*, *PAR_SFM_M* et *PAR_SFM_MV*

La description du jeu de données indique que les variables *PAR_ASE_M*, *PAR_ASE_MV*, *PAR_SFM_M* et *PAR_SFM_MV* ne sont en fait que des combinaisons linéaires et moyennes des autres variables. Ce ne sont pas des variables intrinsèques au jeu de données. On veillera, comme précédemment, à les retirer du jeu de données.

```{r}
data[-p] <- scale(data[-p])
indices <- which(colnames(data) %in% c("PAR_ASE_M", "PAR_ASE_MV", "PAR_SFM_M", "PAR_SFM_MV"))
indices


data$GENRE <- ifelse(data$GENRE=="Jazz", 1, 0)

ggplot(data) + geom_point(aes(x=PAR_SFM_M, y=GENRE), col="blue")  + geom_point(aes(x=PAR_SFM_MV, y=GENRE), col="red")

data <- data[, -indices]
n <- nrow(data)
p <- ncol(data)
dim(data)


plot((data$PAR_ASE_M),(data$PAR_SFM_M),col=data$GENRE+1,pch=data$GENRE+1,cex=data$GENRE+1)

myplot = function(x,Y,xlab=""){
  plot(x,Y,xlab=xlab, col=Y+1,pch=Y+1);
  boxplot(x~Y,xlab=xlab,horizontal=TRUE)
}





myplot(data$PAR_ASE_M,data$GENRE,"PAR_ASE_M")
myplot(data$PAR_ASE_MV,data$GENRE,"PAR_ASE_MV")
myplot(data$PAR_SFM_M,data$GENRE,"PAR_SFM_M")
myplot(data$PAR_SFM_MV,data$GENRE,"PAR_SFM_MV")
```
(Il reste bien 165 variables pour 4278 vecteurs de données.)










## Echantillon d'apprentissage

Dans le but de continuer notre analyse et de pouvoir utiliser la fonction glm par la suite, il nous faut créer une variable catégorielle y qui prenne comme valeur uniquement 0 et 1 selon le genre de l'échantillon.
On choisira donc arbitrairement le Jazz vaut 1 et le classique vaut 0.

```{r}
set.seed(103)
data.old <- read.csv("Music_2023.txt",sep=";",header=TRUE)

names(data)[p] = "y"
names(data.old)[p] = "y"

data$y <- ifelse(data$y=="Jazz", 1, 0)
data.old$y <- ifelse(data$y=="Jazz", 1, 0)

## echantillon d'entrainement
train = sample(c(TRUE,FALSE), n, rep=TRUE, prob=c(2/3,1/3))
data.train <- data[which(train),]
data.old.train <- data.old[which(train),]

## echantillon test
data.test <- data[which(train==FALSE),]
data.old.test <- data.old[which(train==FALSE),]

dim(data.train)
dim(data.old.train)
dim(data.test)
dim(data.old.test)
```

## Estimation de modèle

On commence par créer nos différents modèles à l'aide de la fonction glm du package stats.


```{r Définition des modèles,include=TRUE}
## Définition de Mod0

Mod0 <- glm(y~PAR_TC+PAR_SC+PAR_SC_V+PAR_ASE_M,PAR_ASE_MV+PAR_SFM_M+PAR_SFM_MV, family=binomial, data=data.old.train)
summary(Mod0)

## Définition de ModT
ModT <- glm(y~., family=binomial, data=data.train)
summary(ModT)

## On récupère les p-value des variables
p_value <- coef(summary(ModT))[-1,4]

## On sélectionne celles qui ont un niveau de significativité de 5% et on crée la formule de notre modèle Mod1
index.var.Mod1 <- which(p_value>0.05)
var.Mod1 <- names(data[index.var.Mod1])
formula.Mod1 <- as.formula(paste("y ~",paste(var.Mod1, collapse= "+")))

Mod1<-glm(formula <- formula.Mod1, family=binomial, data=data.train)

## On sélectionne celles qui ont un niveau de significativité de 20% et on crée la formule de notre modèle Mod2
index.var.Mod2 <- which(p_value>0.2)
var.Mod2 <- names(data[index.var.Mod2])
formula.Mod2 <- as.formula(paste("y ~",paste(var.Mod2, collapse= "+")))

Mod2 <- glm(formula=formula.Mod2, family=binomial, data=data.train)
```


```{r stepAIC,include=TRUE}
library(MASS)

## Attention execution longue

step <- stepAIC(ModT)
```

Modèle final:
```{r Formule du modèle AIC, include=TRUE}
## Selection des variables eliminees
#removed.variables <- gsub('- ', '', step$anova$Step[-1])
#variable.names <- names(data)[-p]

## Selection des variables à garder
#keep.indices <- ifelse(variables %in% removed.variables, FALSE, TRUE) %>% which()
#variables.AIC <- variable.names[keep.indices]

## Creation de la formule
#formula.AIC <- as.formula(paste("y ~",paste(variables.AIC, collapse= "+")))
#formula.AIC
```

```{r Définition du modèle AIC}
## Modèle final
#ModAIC <- glm(formula=formula.AIC, family=binomial, data=data.train)
```



## Courbes ROC


```{r Courbe ROC,echo=FALSE}
# On commmence par importer toutes nos variables qui sont st

load("step.RData")
## ModT apprentissage
predproba_train_ModT=predict(ModT,type="response") # ModT est le résultat de glm
pred_train_ModT = prediction(predproba_train_ModT,data.train$y) 
AUC_train_ModT<-round(performance(pred_train_ModT, 'auc')@y.values[[1]],2) #AUC



## ModT test
predproba_test_ModT=predict(ModT,newdata=data.test,type="response")
pred_test_ModT=prediction(predproba_test_ModT,data.test$y)
AUC_test_ModT<-round(performance(pred_test_ModT, 'auc')@y.values[[1]],2) #AUC



## Mod0 test

predproba_test_Mod0=predict(Mod0,newdata=data.test,type="response")
pred_test_Mod0=prediction(predproba_test_Mod0,data.test$y)
AUC_Mod0<-round(performance(pred_test_Mod0, 'auc')@y.values[[1]],2) #AUC

## Mod1 test

predproba_test_Mod1=predict(Mod1,newdata=data.test,type="response")
pred_test_Mod1=prediction(predproba_test_Mod1,data.test$y)
AUC_Mod1<-round(performance(pred_test_Mod1, 'auc')@y.values[[1]],2) #AUC

## Mod2 test

predproba_test_Mod2=predict(Mod2,newdata=data.test,type="response")
pred_test_Mod2=prediction(predproba_test_Mod2,data.test$y)
AUC_Mod2<-round(performance(pred_test_Mod2, 'auc')@y.values[[1]],2) #AUC


## ModAIC test

predproba_test_ModAIC=predict(ModAIC,newdata=data.test,type="response")
pred_test_ModAIC=prediction(predproba_test_ModAIC,data.test$y)
AUC_ModAIC<-round(performance(pred_test_ModAIC, 'auc')@y.values[[1]],2) #AUC

## Définition de nos légendes
l_train_ModT<-paste("Apprentissage ModT, AUC=",AUC_train_ModT,sep=" ")
l_test_ModT<-paste("Test  ModT, AUC=",AUC_test_ModT,sep=" ")
l_Mod0<-paste("Test Mod0, AUC=",AUC_Mod0,sep=" ")
l_Mod1<-paste("Test Mod1, AUC=",AUC_Mod1,sep=" ")
l_Mod2<-paste("Test Mod2, AUC=",AUC_Mod2,sep=" ")
l_AIC<-paste("Test ModAIC, AUC=",AUC_ModAIC,sep=" ")

## Tracé de nos courbes ROC

plot(performance(pred_train_ModT,"sens","fpr"),xlab="",col="black",main="Courbes ROC de nos différents modèles") # ROC
plot(performance(pred_test_ModT,"sens","fpr"),xlab="",col="purple",add=TRUE)
plot(performance(pred_test_Mod0,"sens","fpr"),xlab="",col="blue",add=TRUE)
plot(performance(pred_test_Mod1,"sens","fpr"),xlab="",col="yellow",add=TRUE)
plot(performance(pred_test_Mod2,"sens","fpr"),xlab="",col="green",add=TRUE)
plot(performance(pred_test_ModAIC,"sens","fpr"),xlab="",col="orange",add=TRUE)
abline(a=0, b=1, col="#33FF66",lty=2)
abline(v=0,col="#003300",lty=2)
abline(h=1,col="#003300",lty=2)


legend("bottomright",legend=c(l_train_ModT,l_test_ModT,l_Mod0,l_Mod1,l_Mod2,l_AIC,"Règle aléatoire","Règle Parfaite"),lty=c(1,1,1,1,1,1,2,2),col=c("black","purple","blue","yellow","green","orange","#33FF66","#003300"))
```


On peut alors comparer l'aire sous la courbe pour classer nos meilleures règles de décision.
On constate logiquement que le les prédictions sur le jeu d'apprentissage de ModT sont très précises ce qui était attendu.

Toutefois, les performances de ModT sur les données test sont aussi très bonnes et il apparaît qu'avec ModAIC ce sont les deux meilleurs modèles. 

En outre, on remarque que Mod0 est très peu performant et se rapproche d'un choix aléatoire, ceci est dû que les variables retenues sont très peu nombreuses et ne sont pas des variables intrinsèques de notre jeu de donnée (comme évoqué précédemment). 

Enfin, on remarque que Mod1 et un bon modèle alors que Mod12 a des performances plutôt faibles sûrement dues au fait que l'on considère peu de variables dans ce modèle.

## Erreurs

On souhaite maintenant comparer nos modèles à l'aide de l'erreur effectuée sur l'échantillon d'apprentissage puis sur l'échantillon de test

```{r Calcul des prédictions pour les modèles sur le jeu d apprentissage sauf pour ModT,include=TRUE}

predproba_train_Mod0=predict(Mod0,type="response") 
predproba_train_Mod1=predict(Mod1,type="response") 
predproba_train_Mod2=predict(Mod2,type="response") 
predproba_train_ModAIC=predict(ModAIC,type="response") 




```

Dès lors, on peut calculer nos erreurs de classification et les ranger dans un tableau (cf ci-dessous).


```{r Calcul des erreurs pour nos différents modèles sur échantillon test et apprentissage,echo=FALSE}

## On commence par créer des vecteurs de 0 et de 1, 1 si notre prédiction est >=0.5 , 0 sinon 

## ModT

class_train_ModT=ifelse(predproba_train_ModT>=0.5,1,0)
class_test_ModT=ifelse(predproba_test_ModT>=0.5,1,0)

## Mod0

class_train_Mod0=ifelse(predproba_train_Mod0>=0.5,1,0)
class_test_Mod0=ifelse(predproba_test_Mod0>=0.5,1,0)

## Mod1

class_train_Mod1=ifelse(predproba_train_Mod1>=0.5,1,0)
class_test_Mod1=ifelse(predproba_test_Mod1>=0.5,1,0)

## Mod2

class_train_Mod2=ifelse(predproba_train_Mod2>=0.5,1,0)
class_test_Mod2=ifelse(predproba_test_Mod2>=0.5,1,0)

## ModAIC

class_train_ModAIC=ifelse(predproba_train_ModAIC>=0.5,1,0)
class_test_ModAIC=ifelse(predproba_test_ModAIC>=0.5,1,0)

## Calcul des erreurs

## ModT
err_train_ModT<-round(mean(class_train_ModT!=data.train$y),3)
err_test_ModT<-round(mean(class_test_ModT!=data.test$y),3)



## Mod0

err_train_Mod0<-round(mean(class_train_Mod0!=data.train$y),3)
err_test_Mod0<-round(mean(class_test_Mod0!=data.test$y),3)

## Mod1

err_train_Mod1<-round(mean(class_train_Mod1!=data.train$y),3)
err_test_Mod1<-round(mean(class_test_Mod1!=data.test$y),3)

## Mod2 

err_train_Mod2<-round(mean(class_train_Mod2!=data.train$y),3)
err_test_Mod2<-round(mean(class_test_Mod2!=data.test$y),3)


## ModAIC

err_train_ModAIC<-round(mean(class_train_ModAIC!=data.train$y),3)
err_test_ModAIC<-round(mean(class_test_ModAIC!=data.test$y),3)

err_train<-c(err_train_ModT,err_train_Mod0,err_train_Mod1,err_train_Mod2,err_train_ModAIC)
err_test<-c(err_test_ModT,err_test_Mod0,err_test_Mod1,err_test_Mod2,err_test_ModAIC)

err<-data.frame(Apprentissage=err_train,Test=err_test)

rownames(err)<-c("ModT","Mod0","Mod1","Mod2","ModAIC")

print(err)









```